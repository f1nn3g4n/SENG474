{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPewai3ilacYvfc4FV1Kbel"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Problem 1. American Handwriting"],"metadata":{"id":"iNvi8uHxvRa0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ow2JXCv7swuh"},"outputs":[],"source":["# import pandas as pd\n","# import numpy as np\n","# from keras.datasets import mnist\n","\n","# (train_X, train_y), (test_X, test_y) = mnist.load_data()"]},{"cell_type":"markdown","source":["Don't run the mnist until you are ready. You get x amount of resources for google collab per month apparently."],"metadata":{"id":"s4xFDYDjztIh"}},{"cell_type":"markdown","source":["# Part 1: Derivative"],"metadata":{"id":"sxmaAoVsvaa1"}},{"cell_type":"markdown","source":["*f*(x)$_i$ = $\\frac{e_i^x}{\\sum_je_j^x}$ \n","\n","gradient = $\\begin{cases} f(x)_i(1-f(x)_i) & j = i\\\\-f(x)_if(x)_j & j\\ne i \\end{cases}$"],"metadata":{"id":"poFUkX--tItj"}},{"cell_type":"code","source":["import math\n","import numpy as np\n","# help from: https://slowbreathing.github.io/articles/2019-05/softmax-and-its-gradient\n","def softmax(vector):\n","  ''' Takes a vector (np.array) and returns softmax matrix '''\n","  result = []\n","  for row in vector:\n","    vals = np.asarray(row)\n","    result.append(np.exp(vals)/float(sum(np.exp(vals))))\n","\n","  return np.array(result)\n","\n","def softmax_gradient(vector):\n","  ''' \n","  Takes a softmax vector (np.array) and returns the softmax gradient matrix \n","  '''\n","  matrix = np.diag(vector)\n","  for i in range(len(matrix)):\n","    for j in range(len(matrix)):\n","      if i == j:\n","        matrix[i][i] = vector[i] * (1-vector[i])\n","      else:\n","        matrix[i][j] = -vector[i]*vector[j]\n","  return matrix"],"metadata":{"id":"qX8_XeEsyHz3","executionInfo":{"status":"ok","timestamp":1666914108801,"user_tz":420,"elapsed":118,"user":{"displayName":"Finn","userId":"01146107018286362364"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Test run of softmax and gradient\n","x = np.array([[1,3,5,7]])\n","sm = softmax(x)\n","print(sm[0])\n","sm_grad = softmax_gradient(sm[0])\n","print()\n","print(sm_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g17LHq6P0S5U","executionInfo":{"status":"ok","timestamp":1666914192511,"user_tz":420,"elapsed":112,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"61049c10-8ae2-4476-8ba7-fc10e6e09529"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.00214401 0.0158422  0.11705891 0.86495488]\n","\n","[[ 2.13941201e-03 -3.39658185e-05 -2.50975338e-04 -1.85447085e-03]\n"," [-3.39658185e-05  1.55912258e-02 -1.85447085e-03 -1.37027892e-02]\n"," [-2.50975338e-04 -1.85447085e-03  1.03356124e-01 -1.01250678e-01]\n"," [-1.85447085e-03 -1.37027892e-02 -1.01250678e-01  1.16807938e-01]]\n"]}]},{"cell_type":"markdown","source":["# Part 2: Simple"],"metadata":{"id":"eRdntJGI0IhP"}},{"cell_type":"markdown","source":["\n","%%time gives the current time, use to determine which is faster\n","Python Engineer on YouTube has good from scratch vids"],"metadata":{"id":"qnfj36Aqx7HD"}},{"cell_type":"markdown","source":["make sure keras input layer dimension should correspond with your scratch program"],"metadata":{"id":"F5ojul3c0Bnm"}},{"cell_type":"markdown","source":["follow up on learning rate for keras in 3. keep it simple"],"metadata":{"id":"_5atbKxn0kKI"}},{"cell_type":"markdown","source":["In later hidden layers, could be smaller, eventually getting into the 10 node output layer"],"metadata":{"id":"7a8ugwpG2idt"}},{"cell_type":"code","source":["# help from: https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n","\n","class NeuralNet:\n","  def __init__(self):\n","    self.layers = []\n","  \n","  def add(self, layer):\n","    self.layers.append(layer)\n","\n","  def fit(self, x_train, y_train, iterations, learn_rate):"],"metadata":{"id":"m05YDwTm2hr_"},"execution_count":null,"outputs":[]}]}